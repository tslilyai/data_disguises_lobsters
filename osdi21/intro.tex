%-------------------------------------------------------------------------------
\section{Introduction}
%-------------------------------------------------------------------------------

\subsection{Motivation} 

Web application companies face increasing legal requirements to protect users’ data. These
requirements pressure companies to properly delete and anonymize users' data when a user requests to
\emph{unsubscribe} from the service (i.e.,\ revoke access to their personal data).
For example, the GDPR requires that any user data remaining after a user unsubscribes is
\emph{decorrelated}, i.e., cannot be (directly or indirectly) used to identify the user~\cite{gdpr}.  

Furthermore, keeping identifying and personal data when no longer strictly necessary increases
companies' liability: the GDPR and other laws mandate that companies retain only user data that is
relevant and necessary for their applications' purposes. To increase users' control over their data
and decrease the amount of incriminating data stored in the application at any one point, users
should be able to freely unsubscribe from the service to enter a privacy-preserving mode, and later
resubscribe when they wish to use the service. \lyt{(this seems unconvincing, should come up with better
motivation?)}

\subsection{Goals} 
\sys's goal is to provide the following properties while preserving an application's 
semantics: 
\begin{itemize} 
    \item Decorrelation: Decorrelation ideally guarantees that it is impossible to distinguish
        between two records formerly associated with the same unsubscribed user and two records from
        different unsubscribed users.  
    %\item Deletion Correctness: Deletion of user records should correctly conform to application
        %semantics: for example, post deletion could remove the post and its underlying comments, or
    %simply anonymize the post and keep all content accessible.  
    \item Resubscription: Users should be able to easily switch between a privacy-preserving unsubscribed mode 
       and an identity-revealing subscribed mode, without permanently losing their application data.  
\end{itemize}

\sys~must implement these properties while ensuring (1) performance comparable to today’s
widely-used databases, and (2) easy adoption (decorrelation should be
automated and not require modifications to application schemas or semantics).

\subsection{Decorrelation Guarantees} 

We address applications in which application data consists of \emph{data records} and computations
(such as aggregations) that may be performed over these data records. Data records are considered
sensitive, private data records when they contain \emph{user identifiers}; for example, a row in a
table containing a column of user IDs would be a user's private data record. Data records containing
multiple, potentially different, user IDs are considered shared data records private to the
identified users.

Perfect decorrelation is achieved when queries to the application reveal no information allowing an
observer to determine if two user data records with different user IDs belong to the same user who
has since unsubscribed (are \emph{linked}), or belong to two different users. Observers gain no
information that allows them to distinguish the two scenarios~\lyt{Not sure how to define
``distinguish'' formally---equally probable? Perhaps noninterference can be cited here)}.

In practical settings, however, perfect decorrelation is likely impossible: for example, a reposted
screenshot may leak user IDs. Furthermore, an observer who can see application queries over time, or
search web archives, can detect when a user unsubscribes and refer to prior snapshots in which user
data records may have had the same user ID.  Given these limitations, we seek to achieve the maximum
decorrelation guarantees possible while assuming that the content of user data does not itself leak
identifying information, and that observers cannot access past application database
state.~\lyt{Note: UIDs can also include things like email addrs, phone number, etc; so the notion of
``identifiers'' might be more broad than stated here}.

\paragraph{Global Placeholder.}
A common strawman solution to decorrelation is to replace all unsubscribed user IDs with one global
placeholder ID. 

This results in the following privacy guarantees~\lyt{how to formalize? probability stuff...}
\begin{itemize}
    \item Extremely Unprivate: If only one user ever unsubscribes, all remnants can be linked back
        to that user's identity.
    \item Extremely private: If all users unsubscribe, two remnants are equally as likely to belong
        to two individual users as they are to belong to one single user (assuming the number of
        users is unknown and follows some distribution... \lyt{I need to think about this a bit
        more, but I think the intuition is clear}).
\end{itemize}
The amount of linkable information~\lyt{(need to define this)}, and the resulting deviance from
perfect decorrelation, decreases as more users unsubscribe.~\lyt{not sure by how much though}.

Furthermore, a global placeholder makes resubscription challenging: users can no identify which
unsubscribed data records belong to them if all user-specific data has been erased from the
system. 

\paragraph{Data-Record Ghost IDs.}
To support stronger decorrelation guarantees while support resubscription, \sys~generates a unique
ghost user for each data remnant. These ghosts, unlike a global placeholder, are
indistinguishable from a real user in the system, ensuring that queries cannot correlate two ghosts
with a single real (albeit unsubscribed) user. 
\sys~relies on coarse-grained schema annotations to
establish which associations to decorrelate, and builds a dataflow computation resulting in
materialized views that answer application queries. Use of dataflow automatically propagates the
correct updates to materialized views.

However, some linkable information is still leaked. For example, ghost users may be randomly
generated in a pattern identifiable by an observer (e.g.,\ if all ghosts have usernames which are
random numbers, or arbitrary animals, but a real user may have more human-friendly usernames).

\lyt{How to tie in differential privacy? Where there is some privacy budget that is lost on each
query...? Maybe an observer needs to know the distribution of usernames in order to determine that
there is a pattern that is machine-generated?}

\lyt{Or maybe there is some notion of noninterference we could use here? How do \sys's responses to
queries deviate from what an ideally decorrelated system would produce?}

Unlike a global placeholder, \sys~allows users to reactivate their account and undo
the decorrelation: user IDs can be linked back to a set of unique ghost IDs. 
This gives users the ability to freely unsubscribe to protect their privacy
without worrying about losing their accounts. \sys~resubscribes users by transparently propagating
updates to materialized views to expose real user identifiers in place of ghost identifiers. 



