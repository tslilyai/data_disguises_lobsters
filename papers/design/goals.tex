%-------------------------------------------------------------------------------
\section{Setting and Goals}
%-------------------------------------------------------------------------------
Our design considers typical database-backed applications that link a library implementing our disguising
tool (\sys).
%
\sys provides an API that the application uses to specify disguises, apply them, and (in some
cases), reveal disguised data with proper authorization (Table~\ref{tab:client_api}).
%
\sys executes the database transformations required as part of a disguise, and stores
disguised data in a secure way, subject to the threat model we describe in \S\ref{s:threat}.

\subsection{Use Cases \sys Should Support}

\head{Example: HotCRP.}
We imagine three useful disguises that aid privacy in HotCRP: 
\begin{enumerate}
    \item Per-user GDPR Account Deletion, which
        removes all of a particular user's data such as reviews and papers.
    \item Universal Comment Removal, which removes all comments on papers.
    \item Universal Decorrelation, which decorrelates users from
        their authored reviews and papers. Decorrelation of a paper or review (1) generates an
        anonymous user in the user table, and (2) rewrites the foreign key from the paper or review
        to the users table to point to the newly created anonymous user.
\end{enumerate}

Users who invoke GDPR deletion are given the option to return by revealing their disguise; however,
between disguising and revealing their account, no other entity learns the identity or existence of
the user (ensuring that the disguise complies with the GDPR).

After several years, the admin can decay identifiers in the conference data by decorrelating all
users from their authored reviews and papers.  The admin may later decide that arbitrary text in
paper comments also identifies their authors, and invoke universal comment removal.  Both disguises
help protect reviewers and paper authors from being unblinded in the case of a data breach.

Account decorrelation should not prevent the application of universal comment removal
or any other disguise on decorrelated data: disguises should be able to operate on top of
already-disguised data, and if revealed, return the data to the previously disguised state. 
In particular, if the initial disguise missed removing some identifying information, the
application developer can simply write a new disguise to fix it.

Even after universal decorrelation, it would be nice if HotCRP allowed users to still apply GDPR
account deletion to delete (even decorrelated) papers and reviews that they wrote: a disguise that
applies to a user's data may, in some circumstances, apply to data decorrelated from the user.

Finally, HotCRP would retain much of its usefulness if users could be permitted to view reviews on
their papers, or edit their reviews, even if these papers and reviews have been decorrelated and
belong to anonymous users.  However, this should be possible \emph{without} revealing to other users
of the system which actual user authored these anonymized papers and reviews.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\head{Usability.} These disguising properties should be achieved with minimal burden on
users. 

When \sys disguises a user's data for universal decorrelation or comment removal, \sys emails a
unique URL (a \emph{capability}) to the user corresponding to that a paper or review only known to
the user. When the user wants to ask for permission to view (or edit, if permitted) the undisguised
paper or review, the user simply has to click the URL link and log into the application. Thus,
application of universal disguises should not require a user to be online in order to gain the
capability to apply further disguises or view their disguised data.

Similarly, when \sys disguises a user's data for GDPR deletion, the invoking user receives a URL
that allows the user to reveal the disguise, restoring their account.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\head{General Use Cases.} 
From the HotCRP example, we generalize a handful of the most beneficial and practical use cases
that \sys should support:

\begin{itemize}
    \item\textbf{1st-Party GDPR-Compliant Disguising and Revealing.}
\sys should support user-invoked disguise(s) to modify, decorrelate and/or delete the user's data and
account that enable applications to meet the requirements of the GDPR's right to be
forgotten.
%
These disguises can optionally be revealable, which enables users to restore the original state of
        disguised data to \eg permanently restore their accounts and/or data ownership.

\item\textbf{3rd-Party Disguising.}
\sys should support universal, administrator-applied disguise to modify, decorrelate, and/or delete
        data of all users in the system.

\item\textbf{Temporary Recorrelation without Database Changes.}
    \begin{itemize}
        \item \emph{For Disguising Decorrelated Data}: 
        A disguise targeting a user's data can, if authorized, also operate on data decorrelated
            from the user by prior disguises without modifying the database's persistent links
            between data and owning users. For example, GDPR account deletion removes user $u$'s
            reviews even if \sys has decorrelated these reviews from $u$.

    \item \emph{For Per-User Revealed Views and Permissions}:
            Users should be able to operate with ownership permissions on data previously correlated
            with their account, but decorrelated by a disguise by, interacting with a personalized,
            temporary database view when they visit their decorrelated data. This should require no
            modifications to the actual database contents.

            For example, a user whose authored papers have been decorrelated can log in and view their
            papers and reviews on their papers.
\end{itemize}

\item\textbf{Disguising of Anonymized Users.}
Data of anonymized users can be later disguised.  For example, universal comment removal removes the
        data of anonymized users.
This allows disguises to be developed over time, and remove identifying data missed by prior
        disguises..
\end{itemize}

\subsection{\sys Abstractions}
\sys supports these use cases by exposing three abstractions to applications:
\begin{itemize}
    \item Application \emph{principals}, which correspond to users of the application, 
	and which are uniquely identifiable (\eg via a user ID).
        %natural persons using the application, and
        %
	We denote an application principal as $p \in P$, where $P$ is the set of all application principals.
	%
    \item Application \emph{pseudoprincipals}, which correspond to anonymous users not tied to any natural
    person, and which are uniquely identifiable (\eg via a user ID).
        %
	Pseudoprincipals are part of the set of application principals $p \in P$.
        %\lyt{I don't see why they should be a different set?}
	%
    \item A disguise $d \in D$ invoked by some principal $p$, which 
        transforms the application database.
        %specification that consists of one or more disguises, $d \in D$, which each specify how \sys 
	%Each invocation of $d$ results in a unique \emph{disguise} $d$, identified by
        %a global disguise sequence number $i$.
        %\lyt{We can imagine the sequence number being split by disguise specification, but it
        %doesn't seem important here? All it needs to be is uniquely identifiable.}
	%
\end{itemize}
%
%
\sys operates on two categories of data:
\begin{enumerate}
    \item \emph{\textbf{Database Contents}}: The application reads and writes database
        contents, which include visible, undisguised and currently-disguised data.
        \sys modifies the data database contents when it applies and reveals disguises.
    \item \emph{\textbf{Disguise Diffs}}: \sys records the set of disguise diffs---which contain the
        original database contents and the modifications performed to them---and uses diffs to
        compose disguises on top of one another, or to reveal the updates done by a disguise. 
\end{enumerate}

\head{Data Access Control.}
The application's normal permissions logic controls data access to database contents. The
application invokes \sys to access and needs to parse diff contents directly: \sys exposes an API
(\S\ref{s:api}) allowing the client or application to learn specific semantic information contained
in diffs (\eg whether a particular principal used to own a now-decorrelated piece of data) if
provided appropriate authorization. Clients can additionally request via \sys to access and use diff
information to reveal or apply disguises.

Access to diffs is controlled by a pair of capabilities: 
\begin{enumerate}
    \item \emph{\textbf{Data Capability \dcapa{pd}}}: Grants read access to disguise diff data
        associated with principal $p$ produced from applying $d$.
    \item \emph{\textbf{Locating Capability \lcapa{pd}}}: Allows locating the disguise
        diffs associated with principal $p$ produced from applying $d$, but grants no 
        access to the diffs' data.
\end{enumerate}

\noindent Possession of the pair of data and locating capabilities \pcapa{pd} is required in
practice to grant read access to disguise diff data.  Each capability in the pair alone is
insufficient: an attacker who can spoof \lcapa{pd} will not be able to access disguise diffs without
\dcapa{pd}, although they can learn that $d$ disguised some of $p$'s data; and an attacker holding
\dcapa{pd} cannot locate the disguise diffs to access without \lcapa{pd}.

%-------------------------------------------------------------------------------
\subsection{Threat Model}
\label{s:threat}
%-------------------------------------------------------------------------------

%
Data disguises protect user information in a web application against external observation
and service compromise.
%
An external observer is a user of the web application (authenticated or unauthenticated) who
observes information exposed through using the application.
%
A service compromise occurs when an attacker compromises the web application and 
gains full access to the server.
%
The attacker therefore can access any data stored, perform any actions the application can
perform, and access any information available to \sys.
%

%
A data disguise guarantees that the disguised data is hidden from any future attackers unless
explicitly revealed by an authorized principal.
%
In particular, an attacker who compromises \sys at time $t$ learns \emph{nothing but}:
\begin{enumerate}[nosep]
  \item the (plaintext) contents of the application database at or after time $t$;
  \item the disguises invoked, and the identity of the principals invoking them, after time $t$; and
  \item the results of revealing, after time $t$, disguises applied prior to $t$.
\end{enumerate}
%
We make standard assumptions about the security of cryptographic primitives: attackers cannot
break encryption and keys stored with non-colluding clients are safe.
%

%
\sys operates in an honest-but-curious setting: even if compromised, \sys faithfully executes
its protocols, but exposes all data accessed to the attacker.
%

\subsection{Security Goals}
%
With this threat model, \sys seeks to meet four security goals:
%

%
\vspace{6pt}\noindent\textbf{\emph{(1) Authorized Disguises.}}
%
Only a client properly authenticated as a principal $p$ who is authorized to invoke $d$ can apply
(and later reveal) the corresponding disguise $d$.
%

%
%\vspace{6pt}\noindent\textbf{\emph{(2) Secure Ownership.}}
%%
%Only a client who has both locating capability \lcapa{pd} and data capability
%\dcapa{pd} can reestablish ownership by $p$ of data previously owned by $p$ but decorrelated by $d$.
%Establishing ownership allows the application to grant permissions to $p$ to act upon data otherwise
%decorrelated from $p$.
%

\vspace{6pt}\noindent\textbf{\emph{(2) Secure Disguise Diffs.}}
%
Only an authenticated principal who provides both locating capability \lcapa{pd} and data capability
\dcapa{pd} can authorize access to the disguise diffs from disguise $d$, as well as any information
(\eg ownership permissions) derived from diffs.
%

\vspace{6pt}\noindent\textbf{\emph{(3) Privacy of Disguise History.}}
%
An attacker cannot learn the set of disguises that have disguised a principal's data.
%
An attacker only learns a disguise $d$ exists if an authenticated principal $p$ provides
locating capability \lcapa{pd} to \sys.

\vspace{6pt}\noindent\textbf{\emph{Non-Goals.}}
%
Under \sys's threat model, the following properties are out of scope:
%
\begin{itemize}
    \item Security of disguised data when an attacker has prior snapshots the system.
    %\item Authorized disguises if an attacker authenticates as a principal $p$. \ms{this seems trivial}
    %\item Security of disguise changes and disguise history applied to $p$ if $p$'s private key, \privk{p}, is compromised.
    %\item Security of disguise changes and disguise history of $d$ applied to $p$ if an
        %authorized client provides \lcapa{pd} and \dcapa{pd}. \ms{as above}
    \item Security of metadata such as the number of disguises applied to, or number of
	disguise change records associated with, a particular principal $p$.
    \item Privacy guarantees about undisguised data: if identifying data about $p$ is not covered by
        disguise specification $d$, it remains visible to attackers after corresponding instance $d$ applies.
        For example, a disguise that leaves contents of posts unmodified does not hide identifying references
	to users in that content.
    \item Hiding whether data is disguised or not. For example, if a post's author is anonymized as ``anonFox'',
        \sys leaks the fact that a post's author has been disguised.
\end{itemize}

