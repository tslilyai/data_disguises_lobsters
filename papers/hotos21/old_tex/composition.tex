\subsection{Reasoning about Multiple Disguises}
\label{sec:multi}

Applications have specific privacy goals that should be achieved when a disguise is applied,
regardless of the history of previously applied disguises. For example, returning to
the disguises of \gdpr and \ca \lyt{We're cutting this out of S2 so much need to include here}, 
HotCRP's privacy goal may be that \gdpr removes the invoking user's reviews
completely, even when applied after other disguises such as \ca. 
Alternatively, HotCRP's goal may be that 
\gdpr simply erases any identifiers tying the user to their reviews. 

If a disguising tool can interpret the application's privacy goals, we describe mechanisms for how
it can achieve these goals, or warn that application that certain disguise interleavings will
violate these goals.
We assume the tool is provided the set of disguise specifications, and whether each disguise is
reversible.
We discuss how these mechanisms in the context of composing two disguises---\gdpr and \ca in HotCRP.
%---which may lend
%insights as to what a general solution that achieves for a disguising tool
%may look like.

The tool can determine (attribute-level) co-dependencies between disguises by using the disguise
specification. This can be done statically, if application disguises are pre-declared, or
dynamically, when a disguise is invoked.  As we show, this co-dependency information comes in handy
when the tool applies disguises.

Suppose HotCRP's privacy goal after a user's \gdpr disguise is that the invoking user's
reviews are removed. The tool has determined that that \gdpr and \ca are co-dependent, and that \ca has already
been applied.
%
If \ca's application is reversible and stores per-user reveal functions in user vaults, then the
disguising tool knows to query the user's vault to temporarily recorrelate the user's reviews with
their identity before applying \gdpr (phase 1--\emph{Prepare}---of disguise application). This
enables the tool to remove the user's reviews when \gdpr is applied.
%This requires the user to grant access to their vault.  If one disguise removes an object that the
%other disguise modified, then the removal takes precedence.
%
%However, if they both modify the same object attribute, a disguising tool establishes no precedence
%between the modifications and applies them in chronological order.  Alternatively, we can imagine
%that the developer could specify a partial ordering between modifications, or our framework could
%restrict the set of possible modifications and establish a precedence order within this set.

However, if \ca is irreversible and the disguising tool \emph{discards} \ca's reveal functions, then
subsequently applying \gdpr may not remove all the user's originally owned reviews. Knowing this
beforehand, the tool could,
before applying any disguise, provide a warning to the application developer that the privacy policy may be violated if \gdpr is
applied after \ca.
%The right solution here is unclear: %one possibility is for 

Suppose instead that HotCRP's privacy goal is that a user's \gdpr disguise erases all identifiers
tying data to the user.
Then the disguising tool can simply execute \gdpr on top of
\ca and achieve an acceptable state: any reviews missed by \gdpr would necessarily have been
anonymized by \ca.  The tool can achieve an acceptable outcome regardless of whether \ca is
reversible because the policy is more flexible.

We imagine that, given some developer input regarding application-specific policies and descriptions
of each disguise and their reversibility, a disguising tool will be able to achieve the desired acceptable
outcome as we describe in the examples above (or provide warnings to the developer about potentially
problematic disguise composition).

\paragraph{Intermixing Disguise Reversals.}
In addition to temporary reversal for the purposes of disguise composition, disguises may also be
explicitly and completely reversed. 
%when disguises intermix with disguise reversals can be derived from the
%application policy.
For example, imagine that \ca and \gdpr both store reveal functions in user vaults. 
%
Depending to HotCRP's privacy goals after \gdpr, \ca followed by a user's \gdpr followed by the
reversal of \ca should ensure that the deleted user's reviews are still anonymized or removed.
Similarly, the user's \gdpr followed by \ca followed by the reversal of the user's \gdpr should also
ensure that the deleted user's reviews are anonymized.

To handle these scenarios, the disguising tool could keep a persistent log of all disguises
performed by the application; any disguises performed between a disguise's application and its
reversal could be applied to any reintroduced data. In the former scenario, \gdpr's removal would
apply to any recorrelated reviews; in the latter scenario, \ca's decorrelation would apply to any of
the user's reintroduced reviews.
