HotOS XVIII Paper #52 Reviews and Comments
===========================================================================
Paper #52 Privacy Heroes Need Data Disguises


Review #52A
===========================================================================

Paper summary
-------------
This paper describes Edna a system for describing and implementing data
disguising. Disguises allow developers to specify how data should be
transformed (e.g., when users request their data to be deleted) in a
declarative fashion. The authors describe the upsides of using data disguises
and impact on performance when performing disguising at run time. They then
call for databases es to be designed to be privacy-aware from the start.

Overall merit
-------------
3. Weak accept

Reviewer expertise
------------------
3. Knowledgeable

Comments for author
-------------------
This is a timely topic and the paper could potentially lead to fun discussions.
My concern with the current paper is that it's really a preview of a full paper
and I'm not sure the system really works. The call to arms is potentially
interesting though. Below are some questions and comments that I hope will help
you improve the work.

- Is data disguising a meaningful privacy mechanism? As far as I can tell most
  of the transformations can still be mapped back to actual users (they are
  guises) and would violate most definitions of privacy.

  As far as I can tell your proposed disguises for deletions would not be GDPR
  or CCPA compliant and would potentially violate reasonable
  copyrights/terms-of-services policies. So, how does this help the developer
  actually implement complex privacy policies?

  What are the "several widely-used web applications"? And would data
  disguising really help?  The anecdotes you describe sound like incorrectly
  implemented policies rather than desirable features. (And in the GDPR case
  should probably be reported.)

- Data decay sounds cool. But what is the privacy benefit? Sounds more like
  temporary loss of attribution.

- How does reversibility work? I imagine web apps changes. Their data models
  change. Trying to restore restore from raw data seems really hard.

- The assumptions on page 3 makes me think this is just as hard to get right as
  it is today. Your proposed system is essentially a way of declaring faceted
  values [A], but developers still need to get the disguises right (how do I
  know if a guise offers any meaningful privacy?), and they need to write code
  that handles guises right (why will they not just get this wrong? manual
  enforcement is hard).

- Why would you implement this at runtime? I.e., where do I want more than one
  guise? It seems like migrations might be the right place to implement privacy
  transformations (if we really care say about deleting data). This would
  eliminate the runtime overhead, the complexity I mention above, etc.

- The security/privacy implications of the system seem hard to reason about.
  Your HotCRP example on pg 4: it seems like you're suggesting that Bob's
  conflicts be removed. Now suppose Bob exercises the "reversibility"; do you
  need to "undelete" the conflicts to make sure they can't read certain data?

Topicality
----------
4. Hot topic (hot now, hot later)

Discussability
--------------
2. Normal



Review #52B
===========================================================================

Paper summary
-------------
The paper argues for integrating in support for data privacy as a base primitive in data applications, by building in the idea of data disguises, where data objects have guises based on what mode the data is in. The paper then discusses a prototype implemented in rust and a case study for Lobsters and HotCRP.

Overall merit
-------------
2. Weak reject

Reviewer expertise
------------------
2. Some familiarity

Comments for author
-------------------
The paper's premise is interesting, the idea of integrating alternate modes for data is a nice alternative to ad-hoc, on-demand approaches to cleaning or anonymizing data after an event requires it, e.g. account deletion.

I have a few issues with the current paper:

1. The idea of guises is interesting, but the ramifications seem under-developed. 
- what are the cons of such an approach? should we apply it universally to all data objects or only sensitive objects to minimize overheads?
- what are the limitations of this approach? I can imagine some types of data lends itself to this easily, identities, images, metadata for rss subscriptions. But some things may work less well, it would be nice to have a bit more thorough and thoughtful discussion of this.
2. the current discussion seems to be very much tied to notions of objects and attributes, so much so that it is hard to tease out the systems design concepts from constraints of this particular implementation choice. would be nice if that was much more decoupled.
3. There just remain a lot of potential questions that are unexplored or even touched up on here. For example, what are the key metrics that the authors are targeting? easy of development, simplicity of design, robustness against potential failure modes are all candidates. But the goals are not clearly stated in terms of different priorities.

Topicality
----------
2. Perennial topic

Discussability
--------------
2. Normal



Review #52C
===========================================================================

Paper summary
-------------
Protecting user privacy is difficult and deleting data when requested by users
(and demanded by GDPR) is difficult. Services would like to make it
easy for departed users to return, and to retain the value of departed users'
data to the platform even if they never come back.

The proposal is to express deletion (and related anonymizations) as a
relational-ish transformation over the underlying data model. This factors
the mechanics of deletion and anonymization out of the application and
into an "deletion engine" in the same way that the relational interface
factors the mechanics of indices and queries out of the application and into
the database engine.

Overall merit
-------------
4. Accept

Reviewer expertise
------------------
4. Expert

Comments for author
-------------------
This is an interesting, relevant, and poorly-studied problem. The proposed
solution offers a disciplined perspective.

I appreciated that the proposal was clear about what it assumed (end of S3).

I wasn't really clear on why we create multiple guises until section 4.3,
and then it all snapped into place. I can see hints about that idea
earlier in the paper (figure 1 has two guises, and sec 3 mentions multiple
guises), but it wasn't obvious *why*. I suggest clarifying that idea in
the intro. My paraphrasing of what I came to understand:
  "When keeping a user's contributions around after the user has been deleted,
  we want to pretend that each contribution came from a different user, to
  prevent observers from correlating them and de-anonymizing the original user.
  Thus, when a user is deleted, we might create as many guises (unique user
  identites, each with unique nicknames) for that user as seperable
  contributions (eg posting records). If the user ever re-joins the system,
  we'll drop that transformation, collapsing the user back to a single
  identity."

The ability to reveal implies your system doesn't *really* delete the data;
I suspect that's not going to be very GDPR-compliant. I don't think regulatory
"delete" means "pretend you don't have the user's data." :v)


Review by Jon Howell <jonh.hotos21@jonh.net>; intentionally unblinded.

Topicality
----------
4. Hot topic (hot now, hot later)

Discussability
--------------
3. Open and outwardly focused: This work will likely generate and benefit
   from discussion



Review #52D
===========================================================================

Paper summary
-------------
This paper argues that "disguises" are a missing feature of existing databases for privacy,
where disguises are a systematic way to generate privacy preserving "transformations" on data.

Overall merit
-------------
2. Weak reject

Reviewer expertise
------------------
3. Knowledgeable

Comments for author
-------------------
Thank you for submitting to HotOS'21. I think the problem you are targetting is relevant, and I appreciated your brief survery of applications.
I think the work is a little early and a bit too vague still, however, to give it a higher score.

To contrast this with information flow control, or polyinstantiated databases, it seems that the owner of the data
gets to determine how the data looks like to *everyone* in your current prototype, is there, alternatively, different
ways to specify these guises for different users (based, for example, the capabilities that they have or their geographical
location).

In general, I would love for you to make the relationship with IFC explicit. It feels like disguises complement IFC in a really nice way,
and form a lovely complement to "whether you should see data", instead asking the question of "how should you see data".

Which transformations are permanent? Is edge decorrelation, for example, a permanent change rather than simply a "disguise"?

This is a general question that I had about your work: if you are only "disguising" the data, how do you actually ensure that the system,
or someone who obtains the raw data of the database does not get to see data? You appear to be focusing on the application view of guises, but
ignoring scenarios in which an adversary "obtains" the data. Would disguided "deleted" data still qualify as deleted for the purpose of GDPR?

If multiple objects are "linked" to each other, how do you deal with potentially conflicting disguises? Does the most restrictive win?
How do you deal with dynamic links/objects, if an update query changes the links of an object? How does your work relate to correctness guarantees
in databases, like serializability? I am asking as you must generate many many queries for some objects, are there consistency requirements that arise?
If you have to execute those in a transaction, could you end up locking up the system due to costs? I would encourage you, in camera ready or in a
next submission, to emphasize those systems considerations.

Unless I missed it, you discussed initially supporting pretty complex disguises policies, but your final example is "DISGUISE id target",
could you include examples of actual disguise policies?

Topicality
----------
3. Trendy topic (hot now, lukewarm later)

Discussability
--------------
1. Self-contained and standalone: This work might not generate or benefit
   from discussion
