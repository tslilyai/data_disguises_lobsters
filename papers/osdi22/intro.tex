\section{Introduction}
Web applications must protect users' data and rights to data privacy as codified in laws
such as the GDPR.
%
Current web applications take an all-or-nothing approach: they either make minimal effort to
provide data privacy (\eg Reddit and Lobsters), or permanently delete users'
data upon request. Either option gives users little fine-grained control over how web applications
retain and use their private data.
%

%
Furthermore, even these efforts are nontrivial, and require careful understanding and manipulation
of the web application's database. Companies with resources such as FB have implemented internal
systems that handle e.g., user account deletion (cite DELF); however, solutions like these fail to
generalize and require time and money that smaller-scale companies may lack.
%

%
We propose a new system architecture for web applications to enable support for \emph{data disguising},
namely transforming users' data stored by the appliaction in a number of privacy-preserving ways.
Data disguising enables data decay (gradual anonymization over time); revealing of disguises (restoration of deleted data by
the user, while providing strong privacy guarantees when deleted); and decorrelation and
temporary recorrelation of users with anonymized data.
\lyt{<-- Fix this.}
Furthermore, data disguising generalizes across web applications, handling the technical 
challenges of securing private data, while being aware of application database schemas and
semantics.

%-------------------------------------------------------------------------------
\subsection{Utility Goals}
%-------------------------------------------------------------------------------
Our design considers typical database-backed applications that link a library implementing our disguising
tool (\sys).
%
\sys provides an API that the application uses to specify disguises, apply them, and (in some
cases), reveal disguised data with proper authorization (Table~\ref{tab:api}).
%
\sys executes the database transformations required as part of a disguise, and stores
disguised data in a secure way, subject to the threat model we describe in \S\ref{s:threat}.

%\subsection{Use Cases \sys Should Support}
\head{Example: HotCRP.}
We imagine three useful disguises that aid privacy in HotCRP: 
\begin{enumerate}
    \item Per-user GDPR Account Deletion, which
        removes all of a particular user's data such as reviews and papers.
    \item Universal Comment Removal, which removes all comments on papers.
    \item Universal Decorrelation, which decorrelates users from
        their authored reviews and papers. Decorrelation of a paper or review (1) generates an
        anonymous user in the user table, and (2) rewrites the foreign key from the paper or review
        to the users table to point to the newly created anonymous user.
\end{enumerate}

Users who invoke GDPR deletion are given the option to return by revealing their disguise; however,
between disguising and revealing their account, no other entity learns the identity or existence of
the user (ensuring that the disguise complies with the GDPR).

After several years, the admin can decay identifiers in the conference data by decorrelating all
users from their authored reviews and papers.  This helps protect reviewers and paper authors from
being unblinded in the case of a data breach.

Even after universal decorrelation, it would be nice if HotCRP allowed users to apply GDPR account
deletion to delete (even decorrelated) papers and reviews that they wrote: a disguise that applies
to a user's data may, in some circumstances, need to apply to data decorrelated from the user.

Application of universal decorrelation also should not prevent the application of universal comment
removal: the admin may decide, after applying universal decorrelation, that arbitrary text in paper
comments also identifies their authors (which are now anonymous users), and invoke universal comment
removal. 
%
This demonstrates how the developer can simply apply a new disguise to fix mistakes in a previously
applied disguise that left some identifying information around, even if the new disguise now applies to
data of anonymous users.

Finally, HotCRP would retain much of its usefulness if users could be permitted to view reviews on
their papers, or edit their reviews, even if these papers and reviews have been decorrelated and
belong to anonymous users.  However, this should be possible \emph{without} revealing to other users
of the system which actual user authored these anonymized papers and reviews.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\head{Usability.} These disguising properties should be achieved with minimal burden on
users. 

When \sys disguises a user's data for universal decorrelation or comment removal, \sys emails a
unique URL (a \emph{capability}) to the user corresponding to that a paper or review only known to
the user. When the user wants to ask for permission to view (or edit, if permitted) the undisguised
paper or review, the user simply has to click the URL link and log into the application. Thus,
application of universal disguises should not require a user to be online in order to gain the
capability to apply further disguises or view their disguised data.

Similarly, when \sys disguises a user's data for GDPR deletion, the invoking user receives a URL
that allows the user to reveal the disguise, restoring their account.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\head{General Use Cases.} 
From the HotCRP example, we generalize a handful of the most beneficial and practical use cases
that \sys should support:

\begin{itemize}
    \item\textbf{1st-Party GDPR-Compliant Disguising and Revealing.}
\sys should support user-invoked disguise(s) to modify, decorrelate and/or delete the user's data and
account that enable applications to meet the requirements of the GDPR's right to be
forgotten.
%
These disguises can optionally be revealable, which enables users to restore the original state of
        disguised data to \eg permanently restore their accounts and/or data ownership.

\item\textbf{3rd-Party Disguising.}
\sys should support disguise applied by users (such as an admin) that modify, decorrelate, and/or delete
    data of other users in the system. For example, universal conference anonymization or
    comment removal alters data not associated with the invoking admin.

\item\textbf{Temporary Recorrelation w/out Database Changes.}
    \begin{itemize}
        \item \emph{For Disguising Decorrelated Data}: 
        A disguise targeting a user's data can, if authorized, also operate on data decorrelated
            from the user by prior disguises without modifying the database's persistent links
            between data and owning users. For example, GDPR account deletion removes user $u$'s
            reviews even if \sys has decorrelated these reviews from $u$.

    \item \emph{For Per-User Revealed Views and Permissions}:
            Users should be able to operate with ownership permissions on data previously correlated
            with their account, but decorrelated by a disguise. Users do so by interacting with a
            personalized, temporary database view when they visit their decorrelated data. This
            should require no modifications to the actual database contents.

            For example, a user whose authored papers have been decorrelated can log in and view
            their papers and reviews on their papers.
\end{itemize}

\item\textbf{Disguising Anonymized Users.}
\sys can disguise data of anonymized users. For example, universal comment removal may removes the
data of anonymized users generated by universal decorrelation.  This allows disguises to be
developed over time, and remove identifying data potentially mistakenly missed by prior
disguises, but which now belongs to anonymous users.
\end{itemize}

\subsection{\sys Abstractions}
\sys supports these use cases by exposing three abstractions to applications:
\begin{itemize}
    \item Application \emph{principals}, which correspond to users of the application, 
	and which are uniquely identifiable (\eg via a user ID).
        %
	We denote an application principal as $p \in P$, where $P$ is the set of all application principals.
	%
    \item Application \emph{pseudoprincipals}, which correspond to anonymous users not tied to any natural
    person, and which are uniquely identifiable (\eg via a user ID).
        %
	Pseudoprincipals are part of the set of application principals $p \in P$.
    A pseudoprincipal may or may not be indistinguishable from a real principal: for example, it 
        may not have an associated password.
	%
    \item A disguise $d \in D$ invoked by some principal $p$, which 
        transforms the application database.
	%
\end{itemize}
%
%
\sys operates on two categories of data:
\begin{enumerate}
    \item \emph{\textbf{Database Contents}}: The application reads and writes database
        contents, which include visible, undisguised and currently-disguised data.
        \sys modifies the data database contents when it applies and reveals disguises.
    \item \emph{\textbf{Disguise Diffs}}: \sys records the set of disguise diffs---which contain the
        original database contents and the modifications performed to them---and uses diffs to
        compose disguises on top of one another, or to reveal the updates done by a disguise.
        Every disguise diff has an associated principal (namely the one associated with the modified data).
\end{enumerate}

\head{Data Access Control.}
The application's normal permissions logic controls data access to database contents. The
application invokes \sys to access and needs to parse diff contents directly: \sys exposes an API
(\S\ref{s:api}) allowing the application to learn specific semantic information contained in diffs
(\eg whether a particular principal used to own a now-decorrelated piece of data) if provided
appropriate authorization. This authorization also allows the application to ask \sys to use diff
information to reveal or apply disguises.

\vspace{6pt}\noindent
Two types of \emph{capabilities} control access to diffs:
\begin{enumerate}
    \item \emph{\textbf{Decryption Capability \dcapa{p}}}: Grants read access to disguise diffs 
        associated with principal $p$.
    \item \emph{\textbf{Locating Capability \lcapa{pd}}}: Allows locating the disguise
        diffs associated with principal $p$ produced from applying $d$, but grants no 
        access to the diffs' data.
\end{enumerate}

\noindent \sys needs both decryption and locating capabilities to access
disguise diffs of disguise $d$. Each capability alone is insufficient: an attacker who can spoof
\lcapa{pd} will not be able to access disguise diffs without \dcapa{p}, although they can learn
that $d$ disguised some of $p$'s data; and an attacker holding \dcapa{p} cannot locate the disguise
diffs to access without \lcapa{pd}.

%-------------------------------------------------------------------------------
\subsection{Threat Model}
\label{s:threat}
%-------------------------------------------------------------------------------

%
Data disguises protect user information in a web application against external observation
and service compromise.
%
An external observer is a user of the web application (authenticated or unauthenticated) who
observes information exposed through using the application.
%
A service compromise occurs when an attacker compromises the web application and 
gains full access to the server.
%
The attacker therefore can access any data stored, perform any actions the application can
perform, and access any information available to \sys.
%

%
A data disguise guarantees that the disguised data is hidden from any future attackers unless
explicitly revealed by an authorized principal.
%
In particular, an attacker who compromises \sys at time $t$ learns \emph{nothing but}:
\begin{enumerate}[nosep]
  \item the (plaintext) contents of the application database at or after time $t$;
  \item the disguises invoked, and the identity of the principals invoking them, after time $t$; and 
  \item all of a principal's disguise diffs acquired prior to time $t$, should the principal authorize access to
      disguise diffs for purposes of revealing or performing some application action after time $t$.
      %time $t$.
      %results of revealing, after time $t$, disguises applied prior to $t$.
\end{enumerate}
%
We make standard assumptions about the security of cryptographic primitives: attackers cannot
break encryption and keys stored with non-colluding clients are safe.
%

%
\sys operates in an honest-but-curious setting: even if compromised, \sys faithfully executes
its protocols, but exposes all data accessed to the attacker.
%

\subsection{Security Goals}
%
With this threat model, \sys seeks to meet four security goals:
%

%
\vspace{6pt}\noindent\textbf{\emph{(1) Authorized Disguises.}}
%
Only a client properly authenticated as a principal $p$ who is authorized to invoke $d$ can apply
(and later reveal) $d$.
%

\vspace{6pt}\noindent\textbf{\emph{(2) Secure Disguise Diffs.}}
%
Only an authenticated principal who provides both locating capability \lcapa{pd} and decryption capability
\dcapa{p} can authorize access to the disguise diffs, as well as any information
(\eg ownership permissions) derived from diffs.
%

\vspace{6pt}\noindent\textbf{\emph{(3) Privacy of Disguise History.}}
%
An attacker cannot learn the set of disguises that have disguised a principal's data.
%
An attacker only learns a disguise $d$ exists if an authenticated principal $p$ provides
locating capability \lcapa{pd} to \sys.

\vspace{6pt}\noindent\textbf{\emph{Non-Goals.}}
%
Under \sys's threat model, the following properties are out of scope:
%
\begin{itemize}
    \item Security of disguised data when an attacker has prior snapshots of the system.
    \item Security of metadata such as the number of disguises applied to, or number of
        disguise diffs associated with, \emph{some} principal (where the principal
        ID is unknown).
    \item Security of metadata when an attacker has \lcapa{pd}: the attacker can learn that $d$
        applied to a particular principal $p$, and the number of disguise diffs for that $p$ and $d$.
    \item Privacy guarantees about undisguised data: if identifying data about $p$ is not covered by
        disguise specification $d$, it remains visible to attackers after corresponding instance $d$ applies.
        For example, a disguise that leaves contents of posts unmodified does not hide identifying references
	to users in that content.
    \item Hiding whether data is disguised or not. For example, if a post's author is anonymized as ``anonFox'',
        \sys leaks the fact that a post's author has been disguised.
\end{itemize}
