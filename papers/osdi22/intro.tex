\section{Introduction}
Web applications must protect users' data and rights to data privacy as codified in laws
such as the GDPR.
%
Current web applications take an all-or-nothing approach: they either make minimal effort to
provide data privacy (\eg Reddit and Lobsters), or permanently delete users'
data upon request. Either option gives users little fine-grained control over how web applications
retain and use their private data.
%

%
Furthermore, even these efforts are nontrivial, and require careful understanding and manipulation
of the web application's database. Companies with resources such as FB have implemented internal
systems that handle e.g., user account deletion (cite DELF); however, solutions like these fail to
generalize and require time and money that smaller-scale companies may lack.
%

%
We propose a new system architecture for web applications to enable support for \emph{data
disguising}, namely transforming users' data stored by the application in a number of
privacy-preserving ways.  Beyond simply transforming data, data disguising enables data decay (gradual anonymization over time);
revealing of disguises (restoration of deleted data by the user, while providing strong privacy
guarantees when deleted); and decorrelation and temporary recorrelation of users with their data for
the purpose of editing anonymized data, or further disguising it. \lyt{<-- Fix this.} Furthermore,
data disguising generalizes across web applications, handling the technical challenges of securing
private data, while being aware of application database schemas and semantics.

\sys, a prototype data disguising library, enables database-backed applications to
easily support secure data disguising and provide better user privacy. \sys's API supports the
abstraction of users and anonymous users as first-class citizens; and provides secure and private
per-user data transformation and storage, subject to the threat model we describe in \S\ref{s:threat}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Motivation}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
To motivate data disguising, we consider how HotCRP, a popular application for conference paper and
review management, can improve user privacy.  HotCRP currently retains data from past conferences
indefinitely, and many conferences often enforce single- or double-blind reviews, meaning that no
one but the reviewer should be able to correlate their reviews or paper comments with their
identity. However, HotCRP's stores reviews indefinitely linked to the identity of the reviewer,
leaving reviewers succeptible to unblinding in case of a data breach.

To improve upon HotCRP's provided user privacy, HotCRP implement the follow disguises using \sys:
\begin{enumerate}
    \item Per-user GDPR Account Deletion: removing all of a particular user's data such as reviews and papers.
    \item Universal Decorrelation: decorrelating users from
        their authored reviews and papers by (1) generating an
        anonymous user, and (2) relinking the paper or review
        to the newly created anonymous user.
    \item Universal Comment Removal: removing all comments on papers.
\end{enumerate}
\sys enables HotCRP to support the following features:
\begin{itemize}
    \item\emph{1st-Party GDPR-Compliant Disguising:}
HotCRP supports user-invoked disguise(s) to modify, decorrelate and/or delete the user's data and
account, meeting the requirements of the GDPR's right to be forgotten.

    \item \emph{1st-Party Disguised Data Restoration}: HotCRP users who invoke GDPR deletion are given the
        option to return by revealing their disguise; however, between disguising and revealing
        their account, no other entity learns the identity or existence of the user (ensuring that
        the disguise complies with the GDPR).

    \item\emph{3rd-Party Disguising.}
\sys supports disguises applied by users (such as an admin) that transform data of other users in the system. For example, universal conference anonymization or
    comment removal alters data not associated with the invoking admin.

\item \emph{Data Decay}: After several years, the admin can decay identifiers in the conference data
    by decorrelating all users from their authored reviews and papers.  This helps protect reviewers
        and paper authors from being unblinded in the case of a data breach.

\item \emph{Temporary Recorrelation with Anonymized Data}: 
Even after universal decorrelation, HotCRP allows users to apply GDPR account
deletion to delete even their decorrelated papers and reviews that they wrote.
%

%
Furthermore, HotCRP users can also view reviews on their papers, or edit their reviews, even if
        these papers and reviews have been decorrelated and belong to anonymous users.  HotCRP users
        interact with a personalized, temporary database view when they visit their decorrelated
        data. 

Data disguising enables temporary recorrelation to support these use cases \emph{without} changing
        the database contents and revealing to other users of the system
which actual user authored these anonymized papers and reviews.

\item \emph{Further Disguising of Anonymized Users' Data}: A disguise such as universal comment
        removal can be applied after universal decorrelation, even though it now applies to data of anonymous users.
This allows disguises to be developed over time, and to remove identifying data potentially mistakenly missed by prior
disguises, but which now belongs to anonymous users.
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Importantly, these disguising properties place minimal burden on users.
%
When HotCRP disguises a user's data for universal decorrelation or comment removal, HotCRP emails
the user a unique URL (a \emph{capability}) that it gets via invoking \sys's API.  When the user
wants to ask for permission to view (or edit, if permitted) the undisguised paper or review, the
user simply has to click the URL link and log into the application. Thus, application of universal
disguises should not require a user to be online in order to gain the capability to apply further
disguises or view their disguised data.

Similarly, when HotCRP disguises a user's data for GDPR deletion, the invoking user receives a URL
that allows the user to reveal the disguise, restoring their account.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{\sys Abstractions}
An application using \sys's API works with the following \sys abstractions:
\begin{itemize}
    \item Application \emph{principals}, which correspond to users of the application, 
	and which are uniquely identifiable (\eg via a user ID).
        %
	We denote an application principal as $p \in P$, where $P$ is the set of all application principals.
	%
    \item Application \emph{pseudoprincipals}, which correspond to anonymous users not tied to any natural
    person, and which are uniquely identifiable (\eg via a user ID).
        %
	Pseudoprincipals are part of the set of application principals $p \in P$.
    A pseudoprincipal may or may not be indistinguishable from a real principal: for example, it 
        may not have an associated password.
	%
    \item Disguises $d \in D$ %invoked by some principal $p$, which 
        that transform the application database.
	%
    \item \emph{Disguise ownership tokens}: metadata produced by a disguise linking
        disguise-produced pseudoprincipals to real-user principals.
    %
    \item \emph{Disguise diff tokens}: metadata recording the \emph{diff} between pre-disguise and
        post-disguise application state.
    %
    \item \emph{Disguise capabilities}: capabilities authorize the holder to access disguise tokens.
\end{itemize}

\head{Data Access Control.}
The application's normal permissions logic controls data access to database contents, and 
\sys requires two types of \emph{disguise capabilities} to control access to disguise tokens:
\begin{enumerate}
    \item \emph{\textbf{Decryption Capability \dcapa{p}}}: Grants read access to tokens (ownership
        and diff) associated with principal $p$.
    \item \emph{\textbf{Location Capability \lcapa{pd}}}: Enables efficiently locating the tokens associated
with principal $p$ produced from applying $d$, but grants no access to the diffs' data.
\end{enumerate}

\noindent \sys needs both decryption and location capabilities to access disguise diffs of disguise
$d$. Each capability alone is insufficient: an attacker who can spoof \lcapa{pd} will not be able to
access disguise diffs without \dcapa{p}, although they can learn that $d$ disguised some of $p$'s
data; and an attacker holding \dcapa{p} cannot \lyt{efficiently?} locate the disguise diffs to access without
\lcapa{pd}.

%-------------------------------------------------------------------------------
\subsection{Threat Model}
\label{s:threat}
%-------------------------------------------------------------------------------

%
Data disguises protect user information in a web application against external observation
and service compromise.
%
An external observer is a user of the web application (authenticated or unauthenticated) who
observes information exposed through using the application.
%
A service compromise occurs when an attacker compromises the web application and 
gains full access to the server.
%
The attacker therefore can access any data stored, perform any actions the application can
perform, and access any information available to \sys.
%

%
A data disguise guarantees that the disguised data is hidden from any future attackers unless
explicitly revealed by an authorized principal.
%
In particular, an attacker who compromises \sys at time $t$ learns \emph{nothing but}:
\begin{enumerate}[nosep]
  \item the (plaintext) contents of the application database at or after time $t$;
  \item the disguises invoked, and the identity of the principals invoking them, after time $t$; and 
  \item all of a principal's disguise tokens acquired prior to time $t$, should the principal authorize access to
      disguise tokens for purposes of revealing or performing some application action after time $t$.
      %time $t$.
      %results of revealing, after time $t$, disguises applied prior to $t$.
\end{enumerate}
%
We make standard assumptions about the security of cryptographic primitives: attackers cannot
break encryption and keys stored with non-colluding clients are safe.
%

%
\sys operates in an honest-but-curious setting: even if compromised, \sys faithfully executes
its protocols, but exposes all data accessed to the attacker.
%

\subsection{Security Goals}
%
With this threat model, \sys seeks to meet four security goals:
%

%
\vspace{6pt}\noindent\textbf{\emph{(1) Authorized Disguises.}}
%
Only a client properly authenticated as a principal $p$ who is authorized to invoke $d$ can apply
(and later reveal) $d$.
%

\vspace{6pt}\noindent\textbf{\emph{(2) Secure Disguise Tokens.}}
%
Only an authenticated principal who provides both location capability \lcapa{pd} and decryption capability
\dcapa{p} can authorize access to the disguise tokens, as well as any information
(\eg ownership permissions) derived from tokens.
\lyt{Again, \lcapa{pd} isn't actually needed...}
%

\vspace{6pt}\noindent\textbf{\emph{(3) Privacy of Disguise History.}}
%
An attacker cannot learn the set of disguises that have disguised a principal's data.
%
An attacker only learns a disguise $d$ applied to $p$'s data if authenticated principal $p$ provides
location capability \lcapa{pd} to \sys.

\vspace{6pt}\noindent\textbf{\emph{Non-Goals.}}
%
Under \sys's threat model, the following properties are out of scope:
%
\begin{itemize}
    \item Security of disguised data when an attacker has prior snapshots of the system.
    \item Security of metadata such as the number of disguises applied to, or number of
        disguise tokens associated with, \emph{some} principal (where the principal
        ID is unknown).
    \item Security of metadata when an attacker has \lcapa{pd}: the attacker can learn that $d$
        applied to a particular principal $p$, and the number of disguise tokens for that $p$ and $d$.
    \item Privacy guarantees about undisguised data: if identifying data about $p$ is not covered by
        disguise specification $d$, it remains visible to attackers after corresponding instance $d$ applies.
        For example, a disguise that leaves contents of posts unmodified does not hide identifying references
	to users in that content.
    \item Hiding whether data is disguised or not. For example, if a post's author is anonymized as ``anonFox'',
        \sys leaks the fact that a post's author has been disguised.
\end{itemize}
