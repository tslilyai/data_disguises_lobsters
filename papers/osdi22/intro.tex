\section{Introduction}
\label{s:intro}

%% Problem statement
%
Web applications today handle copious personal information, much of it
sensitive, and store it for a long time.
%
For example, a user who books a room at a hotel once can find that their
sensitive information like passport and phone numbers was compromised by
an attacker years later~\cite{starwood-hack}.
%
%Users' privacy and their rights to exercise control over their data in these
%applications thus are an increasingly important concern for application
%developers.
%
Many developers want to do a good job providing privacy choices to their users,
and legal requirements (\eg the GDPR, CCPA, and others) increasingly mandate
doing so.
%
%Even beyond meeting the legal requirements, many developers are at least
%worried about the reputational damage of a large-scale data leak.
%
But doing a good job at data privacy is hard: it requires extensive manual
implementation work today, and it is easy to get wrong.
%
As a result, applications lack desirable privacy features, like \eg ways to
remove or anonymize a user's account, or for old data to ``decay'' into
lower-fidelity, less identifying representations over time.
%

%
%Furthermore, even these efforts are nontrivial, and require careful understanding and manipulation
%of the web application's database. Companies with resources such as FB have implemented internal
%systems that handle e.g., user account deletion (cite DELF); however, solutions like these fail to
%generalize and require time and money that smaller-scale companies may lack.
%

%% Our key idea: data disguising
%
This paper describes \emph{data disguising}, a new systematic framework that
provides abstractions that help developers implement correct,
expressive, and end-user-friendly privacy functionality.
%
Data disguises transform a user's data in a web application in
privacy-preserving ways, and thus reduce the damage done when database contents
are exposed to an attacker.
%
Crucially, our framework allows the application to maintain key functionality even
when a user has disguised their data, and supports reversible disguises for users
who want to return to an identity-revealing state.
%

%
To understand the need for data disguising, consider Lobsters, a Reddit-like
discussion forum~\cite{lobsters}.
%
The Lobsters developers already provide an option for a user to delete their own
account, but also permit users to change their mind and reclaim their
account later.
%
As a result, Lobster's account deletion actually merely hides data (\eg user
details, comments, private messages) by marking it as deleted, and optionally
reassigns contributions to a ``inactive user'' placeholder.
%
This allows the user to return, but provides them with no privacy against an
attacker who compromises the server while the user is in deleted state.
%
How could the Lobsters developers try to provide this privacy?
%
One option might be to devise their own cryptographic server-side storage for
deleted users' data; another might have the user export their account data,
delete it in the database, and then cryptographically verify on re-import that
the data has not been tampered with.
%
In either option, the Lobsters developers also need to ensure that the
application continues to work for the remaining users, and protect against
attacks that leverage leftover metadata (such as the tags on deleted users'
posts) to infer the identity of deleted users.
%
These are tough challenges, and developers must solve them anew for each
application today.
%

%
Data disguising provides a reusable library that addresses these challenges.
%
\note{old follows}
%
To address this, we introduce \emph{pseudoprincipals}, which are first-class anonymous
users that serve as stand-ins for disguised users.
%
An disguised principal typically---depending on the level of security and anonymity
desired---has many pseudoprincipals, up to one for each application data object.
%

%
\sys protects users' data against an attacker who completely compromises the
application server, and thus gains access to the full database contents, the server's
memory, and can act with full administrator privileges in the application.
%
Data disguised prior to compromise remains secure as long as the principal
originally associated with the data does not interact with their disguised
data.
%
Further, \sys's metadata---\eg whose data has been disguised in which way---is
hidden from the attacker under the same assumption.
%


%
\sys, our prototype data disguising library, provides data disguising APIs for
database-backed web applications.
%
For example, \sys helps Lobsters~\cite{lobsters}, a Reddit-like discussion platform,
support GDPR-compliant account deletion and anonymization of old contributions; and it
anyonmizes a homework submission system used by the authors~\cite{websubmit-rs-anon}
after the end of course while preserving students' ability to view and edit their
homework.
%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\subsection{Motivation}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%To motivate data disguising, we consider how HotCRP, a popular application for conference paper and
%review management, can improve user privacy.  HotCRP currently retains data from past conferences
%indefinitely, and many conferences often enforce single- or double-blind reviews, meaning that no
%one but the reviewer should be able to correlate their reviews or paper comments with their
%identity. However, HotCRP's stores reviews indefinitely linked to the identity of the reviewer,
%leaving reviewers succeptible to unblinding in case of a data breach.
%
%To improve upon HotCRP's provided user privacy, HotCRP implement the follow disguises using \sys:
%\begin{enumerate}[nosep]
%    \item Per-user GDPR Account Deletion: removing all of a particular user's data such as reviews and papers.
%    \item Universal Decorrelation: decorrelating users from
%        their authored reviews and papers by (1) generating an
%        anonymous user, and (2) relinking the paper or review
%        to the newly created anonymous user.
%    \item Universal Comment Removal: removing all comments on papers.
%\end{enumerate}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Importantly, these disguises place low burden on application developers and end users.
%%
%When HotCRP disguises a user's data for universal decorrelation or comment removal, HotCRP emails
%the user a unique URL that it gets via invoking \sys's API.  When the user
%wants to ask for permission to view (or edit, if permitted) the undisguised paper or review, the
%user simply has to click the URL link and log into the application. Thus, application of universal
%disguises should not require a user to be online in order to gain the capability to apply further
%disguises or view their disguised data.
%
%Similarly, when HotCRP disguises a user's data for GDPR deletion, the invoking user receives a URL
%that allows the user to reveal the disguise, restoring their account.
